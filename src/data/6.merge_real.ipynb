{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把test_real_edge和test_real_nominal合成为一个数据集test_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fileonssd/runway-dataset/lard-dataset\n",
      "/home/yeli/workspace/lard/lard-detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ROOT_DATA = os.environ.get('LARD_DATA_ROOT_PATH')\n",
    "ROOT_PROJECT = os.environ.get('LARD_PROJECT_ROOT_PATH')\n",
    "\n",
    "print(ROOT_DATA)\n",
    "print(ROOT_PROJECT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1811 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1811/1811 [00:00<00:00, 11334.08it/s]\n",
      "100%|█████████████████████████████████████| 1811/1811 [00:00<00:00, 7892.53it/s]\n",
      "\n",
      "\n",
      "Successfully merged the two files (/fileonssd/lard-dataset/annotations/instances_test_real_nominal.json , /fileonssd/lard-dataset/annotations/instances_test_real_edge.json) into /fileonssd/lard-dataset/annotations/instances_test_real.json\n"
     ]
    }
   ],
   "source": [
    "json_file_1 = f'{ROOT_DATA}/annotations/instances_test_real_nominal.json'\n",
    "json_file_2 = f'{ROOT_DATA}/annotations/instances_test_real_edge.json'\n",
    "out_file = f'{ROOT_DATA}/annotations/instances_test_real.json'\n",
    "\n",
    "! python {ROOT_PROJECT}/3rdparty/Merge_COCO_FILES/merge.py {json_file_1} {json_file_2} {out_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['images', 'annotations', 'categories'])\n",
      "dict_keys(['images', 'annotations', 'categories'])\n",
      "dict_keys(['images', 'annotations', 'categories'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(json_file_1, 'r') as f:\n",
    "    data_val = json.load(f)\n",
    "\n",
    "with open(json_file_2, 'r') as f:\n",
    "    data_test = json.load(f)\n",
    "\n",
    "with open(out_file, 'r') as f:\n",
    "    data_merge = json.load(f)\n",
    "\n",
    "\n",
    "print(data_val.keys())\n",
    "print(data_test.keys())\n",
    "print(data_merge.keys())\n",
    "\n",
    "print(len(data_val['images']))\n",
    "print(len(data_test['images']))\n",
    "print(len(data_merge['images']))\n",
    "print(len(data_merge['images'])==len(data_val['images'])+len(data_test['images']))\n",
    "\n",
    "print(len(data_val['annotations']))\n",
    "print(len(data_test['annotations']))\n",
    "print(len(data_merge['annotations']))\n",
    "print(len(data_merge['annotations'])==len(data_val['annotations'])+len(data_test['annotations']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:00<00:00, 21186.63it/s]\n",
      "100%|██████████| 1500/1500 [00:00<00:00, 33632.28it/s]\n",
      "100%|██████████| 311/311 [00:00<00:00, 35404.10it/s]\n",
      "100%|██████████| 311/311 [00:00<00:00, 35654.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.makedirs(f'{ROOT_PROJECT}/datasets/lard/detection/test_real', exist_ok=True)\n",
    "os.makedirs(f'{ROOT_PROJECT}/datasets/lard/detection/test_real/images', exist_ok=True)\n",
    "os.makedirs(f'{ROOT_PROJECT}/datasets/lard/detection/test_real/labels', exist_ok=True)\n",
    "\n",
    "\n",
    "def create_symlink(source_folder, target_folder):\n",
    "    # 遍历源文件夹中的每个文件\n",
    "    for filename in tqdm(os.listdir(source_folder)):\n",
    "        source_file = os.path.join(source_folder, filename)\n",
    "        target_file = os.path.join(target_folder, filename)\n",
    "        os.symlink(source_file, target_file)\n",
    "\n",
    "\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_real_nominal/images', f'{ROOT_PROJECT}/datasets/lard/detection/test_real/images')\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_real_nominal/labels', f'{ROOT_PROJECT}/datasets/lard/detection/test_real/labels')\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_real_edge/images', f'{ROOT_PROJECT}/datasets/lard/detection/test_real/images')\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_real_edge/labels', f'{ROOT_PROJECT}/datasets/lard/detection/test_real/labels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并test_synth+test_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4023/4023 [00:00<00:00, 7264.79it/s]\n",
      "100%|█████████████████████████████████████| 4023/4023 [00:01<00:00, 3549.66it/s]\n",
      "\n",
      "\n",
      "Successfully merged the two files (/fileonssd/runway-dataset/lard-dataset/annotations/instances_test_synth.json , /fileonssd/runway-dataset/lard-dataset/annotations/instances_test_real.json) into /fileonssd/runway-dataset/lard-dataset/annotations/instances_test.json\n"
     ]
    }
   ],
   "source": [
    "json_file_1 = f'{ROOT_DATA}/annotations/instances_test_synth.json'\n",
    "json_file_2 = f'{ROOT_DATA}/annotations/instances_test_real.json'\n",
    "out_file = f'{ROOT_DATA}/annotations/instances_test.json'\n",
    "\n",
    "! python {ROOT_PROJECT}/3rdparty/Merge_COCO_FILES/merge.py {json_file_1} {json_file_2} {out_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2212/2212 [00:00<00:00, 24375.37it/s]\n",
      "100%|██████████| 2212/2212 [00:00<00:00, 34619.69it/s]\n",
      "100%|██████████| 1500/1500 [00:00<00:00, 37403.28it/s]\n",
      "100%|██████████| 1500/1500 [00:00<00:00, 37299.94it/s]\n",
      "100%|██████████| 311/311 [00:00<00:00, 33200.86it/s]\n",
      "100%|██████████| 311/311 [00:00<00:00, 33429.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.makedirs(f'{ROOT_PROJECT}/datasets/lard/detection/test', exist_ok=True)\n",
    "os.makedirs(f'{ROOT_PROJECT}/datasets/lard/detection/test/images', exist_ok=True)\n",
    "os.makedirs(f'{ROOT_PROJECT}/datasets/lard/detection/test/labels', exist_ok=True)\n",
    "\n",
    "\n",
    "def create_symlink(source_folder, target_folder):\n",
    "    # 遍历源文件夹中的每个文件\n",
    "    for filename in tqdm(os.listdir(source_folder)):\n",
    "        source_file = os.path.join(source_folder, filename)\n",
    "        target_file = os.path.join(target_folder, filename)\n",
    "        os.symlink(source_file, target_file)\n",
    "\n",
    "\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_synth/images', f'{ROOT_PROJECT}/datasets/lard/detection/test/images')\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_synth/labels', f'{ROOT_PROJECT}/datasets/lard/detection/test/labels')\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_real_nominal/images', f'{ROOT_PROJECT}/datasets/lard/detection/test/images')\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_real_nominal/labels', f'{ROOT_PROJECT}/datasets/lard/detection/test/labels')\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_real_edge/images', f'{ROOT_PROJECT}/datasets/lard/detection/test/images')\n",
    "create_symlink(f'{ROOT_PROJECT}/datasets/lard/detection/test_real_edge/labels', f'{ROOT_PROJECT}/datasets/lard/detection/test/labels')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
